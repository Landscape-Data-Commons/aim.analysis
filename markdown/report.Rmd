---
title: "Draft `r project.name` Project Analysis Report"
date: 'Report date: `r format(Sys.time(), "%d %B, %Y")`'
description: ''
output:
  html_document:
    css: style.css
    fig_caption: yes
    toc: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
always_allow_html: yes
---

```{r setup, include=FALSE}
## Set up the environmente and define the functions used in creating the report
knitr::opts_chunk$set(echo = TRUE)

#### Standard messages to insert at will
msg1 <- paste0("This graph shows the estimated percentage of the reporting unit in different categories for the specified indicator. ", conf.level, "% confidence intervals (CI) around those estimates are provided as error bars. The yellow bar denotes the landscape criterion, or point at which an objective is deemed to be met or not met as defined in the Sample Design Worksheet.")

msg2 <- paste0("This table gives the analysis results for the specified indicator and reporting unit, and contains the data used to create the graph above.")

msgGrob <- "EXAMPLE\nESTIMATES\nDo not use!"
```

# Introduction

Information about the health of the landscapes the BLM manages is essential to achieve the BLM mission (Federal Land Policy and Management Act of 1976).  That land health information enables the BLM to measure the benefits that these lands and waters provide, understand the effects of multiple uses, and thus create management plans to sustain these landscapes for future generations.

Achieving management goals and objectives on BLM lands requires a structured implementation process whereby management goals are refined into concrete monitoring objectives. These monitoring objectives identify the indicator of interest, acceptable range of values for this indicator (i.e., the benchmark), the type or part of the landscape they apply to (i.e., the benchmark group), the desired percentage of the area achieving this objective, the desired confidence level and the time period over which this indicator will be evaluated. Monitoring data are evaluated against the monitoring objectives and then the user can decide if a management goal is also achieved using those results.

This report presents the monitoring objectives and goals and the results of applying them to field data with the intent to provide information about the health of terrestrial ecosystems. The management goals, monitoring objectives, benchmarks, and reporting units were defined by the user (i.e., field office, district office or state office) in the Terrestrial Benchmark Tool and with spatial data files and supplied to the BLM National Operations Center. Field data used in the analysis were collected on the ground by field biologists who measured and assessed important indicators related to ecosystem health with a focus on cover and composition of plant species, plant height, gaps between plant canopies, and stability of soils. These quantitative measurements and qualitative assessments were collected under the BLM Assessment, Inventory, and Monitoring (AIM) program and were selected because of their relationship to the Land Health Fundamentals (link to page on AIM and Land Health Fundamentals). For more information about AIM, including its probabilistic sampling framework, see: http://aim.landscapetoolbox.org/learn-3/about/.

**It should be noted that all data inputs—management goals, monitoring objectives, benchmarks, field data, reporting unit boundaries, and confidence intervals—are set by the user.** For more information about the format and analysis of these inputs, see the Appendices at the end of this report. Additionally, the glossary (LINK) contains concise definitions of technical terminology used in this document.

This report was generated through partnership among the BLM National Operations Center, USDA-ARS Jornada, and the BLM National Aquatic Monitoring Center.

## Report Purpose and use

The purpose of this report is to purpose of this report is to present monitoring objectives and associated results of applying them to field data with the intent to provide information about ecosystem health across an area of interest (i.e., reporting unit). This information can be used to evaluate whether goals, standards, and/or desired conditions are being achieved within that area of interest, an essential step in adaptive management (Figure 1). Specific management applications include but are not limited to: treatment effectiveness, Land Health Standards evaluation, sage-grouse habitat site-scale analysis, and Resource Management Plan effectiveness. Tables, graphs, and other content from this report can be copied into decision-making documents, or the entire report can be used as an appendix to such documents.

## Report Organization

This report has four main sections.
1. The **introduction** sets the stage.
2. The **data summary** provides contextual information that is helpful for interpreting the results, including the list of indicators, time period, timing of data collection, and maps.
3. The **goals, monitoring objectives, benchmarks, and results summary** section is where results begin. This contains tables of which indicators met specified objectives by reporting unit and a summary of the stated objectives.  These tables can be used by BLM land managers to evaluate whether management goals were were achieved based on monitoring objectives.
4. The **indicator estimates by reporting unit for monitoring objectives** section identifies the condition of each indicator for each monitoring objective in each area of interest (i.e., reporting unit). This section provides more detail about the information in the previous section and can be used as supporting information for the conclusions drawn from those tables.

These are finally followed by the **appendices** contain additional background information on AIM, the core indicators and methods, and the analysis approaches used to generate this report.

## Information Sources

This report summarizes and analyzes information collected from a terrestrial AIM project. The following information sources were used in the analysis presented in this report:

* AIM data from TerrADat were the quantitative monitoring data collected in the field for the project.
* The AIM Terrestrial Benchmark Tool contained the monitoring objectives. Every monitoring objective for an indicator in a benchmark group was defined as a set of condition categories (e.g., "Suitable", "Marginal", and "Unsuitable"), each with benchmark values and—when available—the required percentage achieving desired conditions of the landscape. This was provided by the user.
* The project's Sample Design Database captured all of the technical details of the project sample design (e.g., sample frame, stratification, initial site selections, fate of the monitoring sites, and design weights). This information was used to produce unbiased estimates by adjusting the sample point weights.
* Spatial data files defining the reporting units for which estimates were generated from the AIM data. This was provided by the user.
* (OPTIONAL) - Additional sample points from the BLM Landscape Monitoring Framework to supplement the AIM project data.

The original, narrative description of the project design and monitoring objectives were captured in the project’s Monitoring Design Worksheet which was used to select or create the data sources listed above.

## Interpreting the Results

Results in this report can be used to evaluate whether goals regarding ecosystem health are being achieved across a reporting unit (Figure 1). Success criteria for each goal are specified as measureable monitoring objectives that include a natural resource indicator of interest, benchmarks that define value ranges (i.e., condition categories) for that indicator, and the proportion of a reporting unit that should fall in those value ranges. This report provides statistical estimates of the proportion of the landscape achieving or failing to achieve the monitoring objectives in the forms of tables and graphs. BLM land managers requesting the report supplied relevant goals, monitoring objectives and reporting units as part of the process of designing their monitoring effort (see <http://aim.landscapetoolbox.org/design>). Evaluating whether goals are achieved and make management recommendations is the responsibility of BLM land managers.

Important contextual information to consider when you evaluate whether goals are achieved:

* **Monitoring objectives:** Are benchmarks well-justified and based on best available knowledge? Are required proportions informed by management goals and landscape context?
* **Reporting unit:** Is this appropriate to evaluate whether goals are achieved?
* **Timing of data collection:** Was data collected during an appropriate season for the ecosystem type as well as the goals and objectives for the reporting unit?  Does timing vary between years?  Does data collection timing affect your results?
* **Monitoring site spread:** Are monitoring sites distributed across the area of interest?  Were some areas systematically missed, which could lead to bias?

## Additional Information

For additional information, please see <http://aim.landscapetoolbox.org> or contact <ekachergis@blm.gov>. 

***
# Data Summary {.tabset .tabset-fade .tabset-pills}
The following tabs contain tables and graphs describing the information in this report and the data collection effort. This includes the indicators being considered, the time period of data collection, descriptions of the actual data collection effort relative to the original sampling design, and a map of the monitoring sites and reporting units.

## Map of Study Area, Reporting Units, and Sample Points
The map below is provided for general reference only. It was created from the spatial data stored in the project's Sample Design Database, the reporting units provided for this analysis, and the actual monitoring site locations recorded in TerrADat. The map is dynamic - you can pan and zoom it. Layers may also be toggled on/off to view specific features.

```{r studyMap, echo=FALSE}
# The overview map
map.overview

```

## Indicators included in the report
The following indicators were specified in the AIM Terrestrial Benchmarks Tool and are included in this report:
```{r indicatorsIncluded, echo=FALSE, results='asis'}
  for (indicator in unique(benchmarks$INDICATOR)) {
    cat("\n  * ", indicator,"\n")
  }

```

 
## Time period of the report
This report covers data collected between __`r format(points.benchmarked$DATE.VISITED[order(points.benchmarked$DATE.VISITED)[1]], "%d-%m-%Y")`__ and __`r format(points.benchmarked$DATE.VISITED[order(points.benchmarked$DATE.VISITED)[length(unlist(na.omit(points.benchmarked$DATE.VISITED)))]], "%d-%m-%Y")`__. Timing of the data collection in each year is shown below.

```{r plotDates, echo=FALSE, message=FALSE, warning=FALSE}
# The figure of sampling dates
dates.plot

```

## Data Collection Summary
Some sites originally selected as part of a monitoring design will not undergo data collection. For example, selected sites may not be accessible to field crews, or safety concerns may prevent data from being collected. The [Rejection Criteria page on the AIM Landscape Toolbox website](http://aim.landscapetoolbox.org/office-sample-point-evaluation/) describes the rejection criteria and process for evaluating sites. To ensure unbiased estimates of the proportion of the landscape achieving desired conditions, it is important to know the fate of each of the originally-selected sites. The graph below summarizes the fates for every location in the sample design(s) considered in this report. Note that this includes every point that was part of a Sample Design Database used in creating the report, so the counts may be higher than might be initially expected.

**Target sampled** sites are locations on BLM lands where monitoring data were collected. **Inaccessible** sites are on BLM lands, but the data collectors could not physically access the site (e.g., needed to cross private land and access was denied, road was washed out). **Non-target** sites are locations that upon further review were determined to not be on BLM-managed lands. **Unknown** sites are those for which their fate was not recorded. If the necessary information was gained (e.g., condition estimate with desired confidence) without sampling all of the selected points, then any extra points could be marked as **Unneeded** (this is not common).

```{r samplingSummary, error=FALSE, message=FALSE, echo=FALSE}
fates.plot

```


***
# Goals, Monitoring Objectives, Benchmarks, and Results Summary
The following tables summarize the results of this report. They contain land management goals and whether desired conditions, stated as monitoring objectives, were achieved based on available monitoring data in the areas of interest. Monitoring objectives include key indicators of ecosystem health, benchmarks that define desired values of the indicators, and the proportion of the landscape required to meet benchmarks. Monitoring objectives were specified by field office staff in the project's Monitoring Design Worksheet and/or Terrestrial Benchmark Workbook.

BLM land managers can use this information to determine whether goals are being achieved and to recommend changes in management.  If many of the objectives related to a goal are met, then the goal is likely being achieved.  Conversely, if many of the objectives are not met, then the goal is likely not being achieved, and changes in management are necessary.

The Results Summary provides a high level overview. Goals, Objectives, Benchmarks and Results by Reporting Unit provides more detailed results including monitoring objectives and the estimated proportion of the landscape achieving them.

## Results Summary {.tabset .tabset-fade .tabset-pills}
These tables summarize land management goals and whether related monitoring objectives were achieved based on available monitoring data for the reporting units of interest.  Results are separated into two categories: monitoring objectives which are being achieved ("at threshold"), and those that aren't ("no"). Supporting information including the monitoring objectives themselves and estimated area meeting desired condition are in the next section (Goals, Objectives, Results and Benchmarks by Reporting Unit).

```{r lsPropsTables, echo=FALSE,messages=FALSE, warning=FALSE, results='asis'}
# print the summary tables by whether or not meeting objectives
for (val in c("YES","NO","AT THRESHOLD")) {
  d <- reporting.unit.summary.df[grepl(paste(val,"$",sep=""),
                           toupper(reporting.unit.summary.df[, 9])),]
  d <- d[, c(1, 2, 9, 11)]
  names(d) <- c("Goal/Managment Question",
                "Indicator",
                "Objective Met?",
                "Reporting Unit")
  if (nrow(d) > 0) {
    cat("\n### Objectives Met: ", val, "\n")
    print(xtable::xtable(d),
          type = 'html',
          include.rownames = FALSE,
          html.table.attributes = list("border='0' cellpadding='5' class='bordered_table' "))
  }
}
```
## Goals, Objectives, Results and Benchmarks by Reporting Unit {.tabset .tabset-fade .tabset-pills}
The tables below provide supporting information about monitoring objectives and whether they were achieved for each reporting unit. A separate table is presented for each reporting unit.  These tables state the indicators, evaluation groups relative to the benchmark(s) (e.g., "meeting", "unsuitable"), and required proportion of the landscape that should meet desired conditions for each monitoring objective to be achieved. The benchmark values for each indicator, the final component of the monitoring objective, are in the last table.

The tables also report monitoring results. The main result is the estimated proportion of the reporting unit in the different evaluation groups relative to the benchmark(s). `r num2nom(conf.level, capitalize = TRUE)` percent confidence intervals (CI) around those estimates show a range of values that likely includes the true proportion. The table also states whether the monitoring objective was met  based on the estimated proportion compared to the required proportion of the landscape. This information can be used by BLM land managers to determine whether goals are being achieved and to recommend changes in management, if needed.

```{r GORBtables, echo=FALSE,messages=FALSE, warning=FALSE, results='asis'}
# Then print the tables by reporting unit
for (level in reporting.unit.levels) {
  data.reporting.unit.level <- analysis %>% dplyr::filter(Type == level)
  # by specific reporting unit
  for (reporting.unit in unique(data.reporting.unit.level$Subpopulation)) {
    cat("\n### ",reporting.unit,"\n")
    print(reporting.unit.summary.xtables[[reporting.unit]],
          type = 'html',
          include.rownames = FALSE,
          html.table.attributes = list("border='0' cellpadding='5' class='bordered_table' "))
  }
}
```

### Benchmarks
```{r objectivesSummary, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
knitr::kable(bm.table)

```

***

# Indicator Estimates by Reporting Unit for Monitoring Objectives

This section identifies the proportion of land or water resources that is achieving desired values known as benchmarks. This section provides further detail about each row of the table in the previous section. This information can be used as supporting information for the conclusions drawn from the previous section. Specifically, for each indicator, the following are reported:

  * Graph of proportion of the area achieving desired conditions (benchmarks) relative to the required proportion in the monitoring objective
* Table showing the proportion of the area achieving desired conditions (benchmarks) as well as the indicator, benchmark, and required proportion of the landscape
* Map of the reporting unit relative to the sample frame

For the details of each monitoring objective, see "Goals, Objectives, Benchmarks, and Results by Reporting Unit."  Monitoring objectives were determined by the field office in their Monitoring Design Worksheet and/or Terrestrial Benchmark Tool.


```{r conditionResults, echo=FALSE, error=FALSE, message=FALSE, warning=FALSE, results='asis'}
cat("\n## Results by Reporting Unit {.tabset .tabset-fade .tabset-pills}\n")
for (level in reporting.unit.levels) { # by reporting unit level

  #cat("\n",msg1,"\n")
  data.reporting.unit.level <- analysis %>% dplyr::filter(Type == level)
  reporting.units <- unique(data.reporting.unit.level$Subpopulation)
  for (reporting.unit in reporting.units) {
    cat("\n###", level, ": ", reporting.unit, "\n")
    data.reporting.unit <- data.reporting.unit.level %>% dplyr::filter(Subpopulation == reporting.unit)
    mqs <- unique(data.reporting.unit$MANAGEMENT.QUESTION)
    for (mq in mqs) { # by specific reporting unit
      cat("\n#### **Goal/Management Question: ", mq, "**\n")
      data.mq <- data.reporting.unit %>% dplyr::filter(MANAGEMENT.QUESTION == mq)
      Indicators <- unique(data.mq$Indicator)
      for (indicator in Indicators) {  # by indicator
        indicator.name <- indicator.lut$indicator.name[indicator.lut$indicator.tdat == indicator]
        cat("\n#### Indicator: ", indicator.lut$indicator.name[indicator.lut$indicator.tdat == indicator], "\n")
        ## Look up the landscape threshold value for the RU and indicator
        req.prop <- benchmarks.sum[benchmarks.sum$indicator.tdat == indicator & !is.na(benchmarks.sum$Required.Proportion), 4]
        req.prop <- as.numeric(req.prop[1, 1])
        
        if (!is.na(req.prop)) {
          req.prop <- req.prop*100
        } else {
          req.prop <- 0
        }
        
        plot <- indicatorPlot(df = analysis,
                              reporting.unit.level = level,
                              reporting.unit.name = reporting.unit,
                              indicator = indicator,
                              indicator.lut = indicator.lut,
                              mq = mq,
                              threshold = req.prop)
        
        map <- indicatorMap(reporting.unit.level = level,
                         reporting.unit.name = reporting.unit,
                         reporting.units.spdf = reporting.units.spdf,
                         prjarea.spdf = project.area.spdf,
                         samplepts.spdf = points.benchmarked.spdf[points.benchmarked.spdf@data$MANAGEMENT.QUESTION == mq & points.benchmarked.spdf@data$INDICATOR == indicator,])
        
        txt <- grid::textGrob(label = msgGrob,
                              just = "centre",
                              gp = grid::gpar(fontsize = 18,
                                              col = "red"))
        
        gridExtra::grid.arrange(gridExtra::arrangeGrob(map, txt, nrow = 2),
                                plot,
                                ncol = 2,
                                widths = c(1, 3))
        
        cat("\n")
        cat("\n",msg1,"\n")
        cat("\n#### Results Table\n")
        cat(pander::pander(indicatorTable(df = analysis,
                                          reporting.unit.level = level,
                                          reporting.unit.name = reporting.unit,
                                          indicator = indicator,
                                          mq = mq)))
        cat("\n",msg2,"\n")
        cat("\n***\n")
      }
    }
  }
}


```
***
# Appendices

  * [Methods for terrestrial data collection](http://www.landscapetoolbox.org/manuals/monitoring-manual/)
* [Sample design information](http://aim.landscapetoolbox.org/analysis-reporting/reporting/report-appendices/)
* [Analysis methods](http://aim.landscapetoolbox.org/analysis-reporting/reporting/report-appendices/)
* Report Inputs
+ Monitoring Design Worksheet
+ Raw data from TerrADat
+ Terrestrial Benchmark Tool
+ Sample design geodatabase
+ Reporting units spatial data
+ Remote-sensing datasets
