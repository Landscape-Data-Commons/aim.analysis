---
title: "Draft `r project.name` Project Analysis Report"
date: 'Report date: `r format(Sys.time(), "%d %B, %Y")`'
description: ''
output:
  html_document:
    css: style.css
    fig_caption: yes
    toc: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
always_allow_html: yes
---

```{r setup, include=FALSE}
## Set up the environmente and define the functions used in creating the report
knitr::opts_chunk$set(echo = TRUE)

#### Standard messages to insert at will
msg1 <- paste0("This graph shows the estimated percentage of the reporting unit in different categories for the specified indicator. ", conf.level, "% confidence intervals (CI) around those estimates are provided as error bars. The yellow bar denotes the landscape criterion, or point at which an objective is deemed to be met or not met as defined in the Sample Design Worksheet.")

msg2 <- paste0("This table gives the analysis results for the specified indicator and reporting unit, and contains the data used to create the graph above.")

msgGrob <- "EXAMPLE\nESTIMATES\nDo not use!"
```

# Introduction

Information about the health of the landscapes we manage is essential to achieve the BLM mission (Federal Land Policy and Management Act of 1976).  It enables BLM to measure the benefits that these lands and waters provide, understand the effects of multiple uses, and thus create management plans to sustain these landscapes for future generations.

This report provides information about the health of terrestrial and aquatic ecosystems.  This information was collected on-the-ground by field biologists who measure and assess important indicators related to ecosystem health.  In terrestrial ecosystems, they focus on cover and composition of plant species, plant height, gaps between plant canopies, and stability of soils.  In aquatic ecosystems, they focus on water quality, stream morphology, and biological characteristics.  These quantitative measurements and qualitative assessments were collected under the BLM Assessment, Inventory, and Monitoring (AIM) program.   For more information about AIM, see <http://aim.landscapetoolbox.org/learn-3/about/>.

This report also includes relevant standard geospatial datasets.  Some relate to ecosystem health, while others provide contextual information about landscapes such as the management activities occurring there.

This report was generated through partnership among the BLM National Operations Center, USDA-ARS Jornada, and the BLM National Aquatic Monitoring Center.

## Report Purpose and use

The purpose of this report is to describe key indicators of ecosystem health across an area of interest. This information can be used to evaluate whether or not goals, standards, and/or desired conditions are being achieved across BLM lands, an essential step in adaptive management (Figure). Specific management applications include but are not limited to: treatment effectiveness, Land Health Standards evaluation, sage-grouse habitat analysis and Resource Management Plan effectiveness. Tables, graphs, and other content from this report can be pasted into decision-making documents, or the entire report can be used as an appendix to such documents.

The standard core indicators contained in this report are relevant to management questions across all BLM ecosystem types, as identified through the BLM AIM Strategy and related efforts (<BLM Tech Note 440>, <BLM Tech Ref 1735-1>).  This report also contains standard national geospatial datasets managed by the BLM National Operations Center and partners.  These geospatial datasets provide spatial and management context for the standard AIM core indicators.

## Report Organization

This report has five main sections.  The **introduction** sets the stage.  The **data summary** provides contextual information that is helpful for interpreting the results, including the list of indicators, time period, timing of data collection, and maps.

Report results begin with the **goals, monitoring objectives, benchmarks, and results summary** section.  This contains tables of which indicators met specified objectdives by reporting unit, and a summary of the stated objectdives.  These table can be used by BLM land managers to evaluate whether goals or management objectives were achieved. These tables summarize results for all indicators.

The **indicator estimates by reporting unit for monitoring objectives** section identifies the condition of each indicator for each area of interest or reporting unit.  Condition refers to the proportion of land or water resources that is achieving desired values known as benchmarks. This section provides further detail about each row of the table in the previous section and can be used as supporting information for the conclusions drawn from that table. This is followed by the **spatial distribution of core indicators** section which provides remote-sensing-derived maps of various core indicators for the study area.

Finally, the **appendices** contain additional background information on AIM, the core indicators and methods, and the analysis approaches used to generate this reports.

## Information Sources

This report summarizes and analyzes information collected from an AIM project. The following information sources were used in the analysis presented in this report:

  * The Monitoring Design Worksheet summarizes the goals and objectives of the monitoring project.
* AIM data from TerrADat are the quantitative monitoring data collected in the field for the project.
* The AIM Terrestrial Benchmark Tool clearly states the monitoring objectives, including indicators, benchmarks, and required proportion of the landscape. It also contains tabular information defining evaluation strata  (i.e., categories assigned to each sample point for the purpose of evaluating an indicator against a benchmark that may change across a landscape). The tool also provides a count of the number of sites meeting and not meeting objectives.
* The project's Sample Design Database captures all of the technical details of the project sample design (e.g., sample frame, stratification, initial site selections, fate of the monitoring sites, and design weights). This information is used to produce unbiased estimates by adjusting the sample point weights.
* Spatial data files defining the different reporting units for which estimates will be generated from the AIM data.
* (OPTIONAL) - Additional sample points from the BLM Landscape Monitoring Framework to supplement the AIM project data.
* (OPTIONAL) - Remote sensing products such as the Grass/Shrub continuous variable predictions or the Landfire EVT map to supplement the quantitative field-derived estimates.

## Interpreting the Results

Results in this report can be used to evaluate whether goals regarding ecosystem health are being achieved across a landscape. Success criteria for each goal are specified as measureable monitoring objectives that include a natural resource indicator of interest, a benchmark that identifies desired values of that indicator, and the proportion of the landscape that should meet the benchmark. This report provides statistical estimates of the proportion of the landscape achieving the monitoring objectives, in the form of tables, graphs and other information (see summary in objectives, benchmarks, and landscape thresholds or detailed info in condition estimates by objective). BLM land managers requesting the report supplied relevant goals, monitoring objectives and reporting units as part of the process of designing their monitoring effort (see <http://aim.landscapetoolbox.org/design>). Upon receipt, it will be the responsibility of BLM land managers to evaluate whether goals are achieved and make management recommendations.

Consider important contextual information when you evaluate whether goals are achieved:

* Monitoring objectives: Are benchmarks well-justified and based on best available knowledge? Are required proportions informed by management goals and landscape context?
* Reporting unit: Is this appropriate to evaluate whether goals are achieved?
* Timing of data collection: Was data collected during an appropriate season for the ecosystem type as well as the goals and objectives for the reporting unit?  Does timing vary between years?  Does data collection timing affect your results?
* Monitoring site spread: Are monitoring sites distributed across the area of interest?  Were some areas systematically missed, which could lead to bias?

## Additional Information

For additional information, please see <http://aim.landscapetoolbox.org> or contact <ekachergis@blm.gov>. 

***
# Data Summary {.tabset .tabset-fade .tabset-pills}
The following tabs contain tables and graphs describing the information in this report and the data collection effort. This includes the indicators being considered, the time period of data collection, descriptions of the actual data collection effort relative to the original sampling design, and a map of the monitoring sites and reporting units.

## Map of Study Area, Reporting Units, and Sample Points
The map below is provided for general reference only. It was created from the spatial data stored in the project's Sample Design Database, the reporting units provided for this analysis, and the actual monitoring site locations recorded in TerrADat. The map is dynamic - you can pan and zoom it. Layers may also be toggled on/off to view specific features.

```{r studyMap, echo=FALSE}
## Create the study area map - project boundary, sample frame, points sampled (from TerrADat)
## Use leaflet.
bounds <- sp::bbox(project.area.spdf)
m <- leaflet::leaflet(sample.frame.spdf) %>% leaflet::addTiles() %>%
  leaflet::fitBounds(lng1 = bounds[1,1],
                     lat1 = bounds[2,1],
                     lng2 = bounds[1,2],
                     lat2 = bounds[2,2]) %>%
  leaflet::addPolygons(data = sample.frame.spdf,
                       fill = TRUE,
                       stroke = TRUE,
                       color = "tan",
                       fillOpacity = 0.6,
                       weight = 2,
                       group = "BLM Lands") %>%
  leaflet::addPolygons(data = project.area.spdf,
                       fill = FALSE,
                       stroke = TRUE,
                       color = "#222",
                       weight = 3,
                       group = "Study Area") %>%
  leaflet::addPolygons(data = reporting.units.spdf,
                       fill = FALSE,
                       stroke = TRUE,
                       color = "#000",
                       weight = 2,
                       fillOpacity = 0.6,
                       group = "Reporting Units") %>%
  leaflet::addCircleMarkers(data = tdat.spdf,
                            radius = 4,
                            color = "navy",
                            stroke = FALSE,
                            fillOpacity = 0.8,
                            group = "Monitoring Sites") %>%
  leaflet::addLegend(position = "bottomright",
                     colors = c("#222", "tan", "navy", "#000"),
                     labels = c("Study Area Boundary", "BLM Lands", "Monitoring Sites", "Reporting Units")) %>%
  leaflet::addLayersControl(overlayGroups = c("Monitoring Sites", "BLM Lands", "Reporting Units", "Study Area"),
                            options = leaflet::layersControlOptions(collapsed = FALSE)
  )
m

```

## Indicators included in the report
The following indicators were specified in the AIM Terrestrial Benchmarks Tool and are included in this report:
```{r indicatorsIncluded, echo=FALSE, results='asis'}
  inds <- unique(benchmarks$INDICATOR)
  for (ind in inds) {
    cat("\n  * ",ind,"\n")
  }

```

 
## Time period of the report
This report covers data collected between __`r as.Date(min(tdat.spdf$DateVisited))`__ and __`r as.Date(max(tdat.spdf$DateVisited))`__. Timing of the data collection in each year is shown below.

```{r plotDates, echo=FALSE, message=FALSE, warning=FALSE}
  mstartdays <- c(0, 32, 61, 92, 122, 153, 183, 214, 245, 275, 306, 336)
  mnames = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sept", "Oct", "Nov", "Dec")
  ggplot2::ggplot(data = tdat.spdf@data,
                       ggplot2::aes(x = yday, fill = factor(year))) +
    ggplot2::geom_histogram(binwidth = 7) +
    ggplot2::xlim(0, 365) +
    ggplot2::geom_vline(xintercept = mstartdays,
                        color = "white",
                        size = 0.75) +
    ggplot2::scale_x_continuous(breaks = mstartdays,
                                labels = mnames) +
    ggplot2::ggtitle("Number of monitoring sites where data was collected by week") +
    ggplot2::theme(panel.grid.major.x = element_blank(),
                   panel.grid.minor.x = element_blank()) +
    ggplot2::xlab("Week of the year") +
    ggplot2::ylab("Number of Plots") +
    ggplot2::labs(fill = "Year")
```

## Data Collection Summary
Some sites originally selected as part of a monitoring design will not undergo data collection. For example, selected sites may not be accessible to field crews, or safety concerns may prevent data from being collected. The [Rejection Criteria page on the AIM Landscape Toolbox website](http://aim.landscapetoolbox.org/office-sample-point-evaluation/) describes the rejection criteria and process for evaluating sites. To ensure unbiased estimates of the proportion of the landscape achieving desired conditions, it is important to know the fate of each of the originally-selected sites. The graph below summarizes the fates for every location in the sample design(s) considered in this report.

**Target sampled** sites are locations on BLM lands where monitoring data were collected. **Inaccessible** sites are on BLM lands, but the data collectors could not physically access the site (e.g., needed to cross private land and access was denied, road was washed out). **Non-target** sites are locations that upon further review were determined to not be on BLM-managed lands. **Unknown** sites are those for which their fate was not recorded. If the necessary information was gained (e.g., condition estimate with desired confidence) without sampling all of the selected points, then any extra points could be marked as **Unneeded** (this is not common).

```{r samplingSummary, error=FALSE, message=FALSE, echo=FALSE}
ggplot2::ggplot(data = as.data.frame(point.fates),
                ggplot2::aes(x = factor(YEAR),
                             y = n,
                             fill = variable,
                             label = n)) +
  ggplot2::geom_bar(stat = "identity",
                    width = 0.5) +
  ggplot2::coord_flip() +
  scale_fill_manual(values = c("Unneeded" = "#2c7bb6",
                               "Unknown" = "#abd9e9",
                               "Non-target" = "#ffffbf",
                               "Inaccessible" = "#fdae61",
                               "Target Sampled" = "#d7191c")) +
  ggplot2::geom_text(data = subset(as.data.frame(point.fates),
                                   n != 0),
                     ggplot2::aes(label = n, y = n),
                     position = ggplot2::position_stack(vjust = 0.5)) +
  ggplot2::ylab("Number of Original Sample Points") +
  ggplot2::xlab("Year") +
  ggplot2::ggtitle("Summary of Point Fate by Year") +
  ggplot2::labs(fill = "Final Point\nDesignation")

```

## Stratum Sampling Info

The monitoring designs related to this report used stratification as a way to spread monitoring effort across different types of land in the study area. The accuracy of estimates from monitoring data depends on whether or not the strata were adequately sampled. Some sites are not visited for various reasons (e.g., inaccessibility, time ran out; see [Rejection Criteria](http://aim.landscapetoolbox.org/wp-content/uploads/2016/12/RejectionCriteria_161228.pdf)). This does not affect accuracy of estimates as long as: 1) the missed sites do not account for a majority of the selected sites in the design and 2) sites were missed at random (i.e, there was no pattern to which sites had data collected and which were missed).

The table below summarizes the total area of each stratum in the monitoring design and the estimated area sampled during data collectionfor the study area. Looking at the **study area** overall gives a general idea of whether or not there were issues with how the sample data represents the different strata. Proportion of design sites sampled is ideally close to one.  If there are strata with very low sampled proportions (less than 0.5), this may affect the ability to draw inferences beyond the sample data in these strata, which should be more thoroughly evaluated.

```{r stratumSampling, error=FALSE, message=FALSE, echo=FALSE, results='asis'}
strat.sampling.table <- dplyr::select(.data = strata.weights,
                                      Stratum,
                                      Total.pts,
                                      Observed.pts,
                                      Prop.dsgn.pts.obsrvd,
                                      Area.HA,
                                      Sampled.area.HA,
                                      Weight)
names(strat.sampling.table) <- c("Design Stratum (Type of Land)",
                                 "# Design Points",
                                 "# Sampled Points",
                                 "Prop. Design Points Sampled",
                                 "Estimated Stratum Area (ha)",
                                 "Stratum Area Sampled",
                                 "Calculated Point Weight (ha/pt)")

print(xtable::xtable(strat.sampling.table),
      type = 'html',
      include.rownames = FALSE,
      html.table.attributes = list("border='0' cellpadding='5', class='bordered_table' "))
```


***
# Goals, Monitoring Objectives, Benchmarks, and Results Summary
The following tables summarize the results of this report. They contain land management goals and whether desired conditions, stated as monitoring objectives, were achieved based on available monitoring data in the areas of interest. Monitoring objectives include key indicators of ecosystem health, benchmarks that define desired values of the indicators, and the proportion of the landscape required to meet benchmarks. Monitoring objectives were specified by field office staff in the project's Monitoring Design Worksheet and/or Terrestrial Benchmark Workbook.

BLM land managers can use this information to determine whether goals are being achieved and to recommend changes in management.  If many of the objectives related to a goal are met, then the goal is likely being achieved.  Conversely, if many of the objectives are not met, then the goal is likely not being achieved, and changes in management are necessary.

The Results Summary provides a high level overview. Goals, Objectives, Benchmarks and Results by Reporting Unit provides more detailed results including monitoring objectives and the estimated proportion of the landscape achieving them.

## Results Summary {.tabset .tabset-fade .tabset-pills}
These tables summarize land management goals and whether related monitoring objectives were achieved based on available monitoring data for the reporting units of interest.  Results are separated into two categories: monitoring objectives which are being achieved ("at threshold"), and those that aren't ("no"). Supporting information including the monitoring objectives themselves and estimated area meeting desired condition are in the next section (Goals, Objectives, Results and Benchmarks by Reporting Unit).

```{r lsPropsTables, echo=FALSE,messages=FALSE, warning=FALSE, results='asis'}
prop.table <- benchmarks.sum[,c(1, 7, 3, 2, 4, 5)]
prop.table$LS.Prop <- paste(prop.table$Proportion.Relation,
                            prop.table$Required.Proportion*100,
                            "%",
                            sep=" ")
prop.table[prop.table$LS.Prop == "NA NA %", "LS.Prop"] <- ""

tables.hold <- c()
summary.table <- data.frame()
for (lev in ru.levels) { # by reporting unit level
  data.rulevel <- analysis %>% dplyr::filter(Type == lev)
  rus <- unique(data.rulevel$Subpopulation)
  for (ru in rus) { # by specific reporting unit
    prop.table.ru <- addLSProp(prop.table = prop.table,
                               analysis.table = analysis,
                               ru = ru,
                               indicator.lut = indicator.lut,
                               conf.level = conf.level)
    prop.table.ru <-  prop.table.ru[,-c(2, 5, 6, 8)] %>% dplyr::arrange(MANAGEMENT.QUESTION, EVALUATION.CATEGORY)  # sort by mgt question and category
    prop.table.ru <- prop.table.ru %>% dplyr::select(-StdError.P)
    names(prop.table.ru) <- c("Goal/Management Objective",
                              "Indicator",
                              "Category",
                              "Required Percent",
                              "n",
                              "Estimated Percent",
                              "Lower CI",
                              "Upper CI",
                              "Objective Met?")
    prop.table.ru.strip <- prop.table.ru[!(prop.table.ru$Category %in% cats.to.suppress),] # Strip out the categories to suppress
    
    ## Dump these into a list so we can print them out later. Need to first generate the summary table
    tables.hold[[ru]] <- xtable::xtable(prop.table.ru.strip,
                                       align = c("l","l","l","l","c","c","c","c","c","c"))
    
    prop.table.ru$lev <- lev
    prop.table.ru$ru <- ru
    summary.table <- rbind(summary.table,
                           as.data.frame(prop.table.ru))
  }
}

# print the summary tables by whether or not meeting objectives
vals <- c("YES","NO","AT THRESHOLD")

for (val in vals) {
  d <- summary.table[grepl(paste(val,"$",sep=""),
                           toupper(summary.table[, 9])),]
  d <- d[, c(1, 2, 9, 11)]
  names(d) <- c("Goal/Managment Question",
                "Indicator",
                "Objective Met?",
                "Reporting Unit")
  if (nrow(d) > 0) {
    cat("\n### Objectives Met: ", val, "\n")
    print(xtable::xtable(d),
          type = 'html',
          include.rownames = FALSE,
          html.table.attributes = list("border='0' cellpadding='5' class='bordered_table' "))
  }
}
```
## Goals, Objectives, Results and Benchmarks by Reporting Unit {.tabset .tabset-fade .tabset-pills}
The tables below provide supporting information about monitoring objectives and whether they were achieved for each reporting unit. A separate table is presented for each reporting unit.  These tables state the indicators, evaluation groups relative to the benchmark(s) (e.g., "meeting", "unsuitable"), and required proportion of the landscape that should meet desired conditions for each monitoring objective to be achieved. The benchmark values for each indicator, the final component of the monitoring objective, are in the last table.

The tables also report monitoring results. The main result is the estimated proportion of the reporting unit in the different evaluation groups relative to the benchmark(s). `r num2nom(conf.level, capitalize = TRUE)` percent confidence intervals (CI) around those estimates show a range of values that likely includes the true proportion. The table also states whether the monitoring objective was met  based on the estimated proportion compared to the required proportion of the landscape. This information can be used by BLM land managers to determine whether goals are being achieved and to recommend changes in management, if needed.

```{r GORBtables, echo=FALSE,messages=FALSE, warning=FALSE, results='asis'}
# Then print the tables by reporting unit
for (lev in ru.levels) {
  data.rulevel <- analysis %>% dplyr::filter(Type == lev)
  rus <- unique(data.rulevel$Subpopulation)
  for (ru in rus) { # by specific reporting unit
    cat("\n### ",ru,"\n")
    print(tables.hold[[ru]],
          type = 'html',
          include.rownames = FALSE,
          html.table.attributes = list("border='0' cellpadding='5' class='bordered_table' "))
  }
}
```

### Benchmarks
```{r objectivesSummary, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
bm.table <- dplyr::select(.data = benchmarks,
                          MANAGEMENT.QUESTION,
                          INDICATOR,
                          BENCHMARK.SOURCE,
                          EVALUATION.STRATUM,
                          EVALUATION.CATEGORY,
                          EVAL.STRING.LOWER,
                          EVAL.STRING.UPPER,
                          INDICATOR.TDAT)
bm.table$BENCHMARK <- paste(bm.table$EVAL.STRING.LOWER,
                            bm.table$INDICATOR.TDAT,
                            bm.table$EVAL.STRING.UPPER)
bm.table <- dplyr::select(.data = bm.table,
                          -dplyr::starts_with("eval.string"),
                          -INDICATOR.TDAT) %>% dplyr::arrange(MANAGEMENT.QUESTION, EVALUATION.CATEGORY)  # Drop the unneeded fields and sort by mgt question
names(bm.table) <- c("Goal/Management Question",
                     "Indicator",
                     "Benchmark Source",
                     "Evaluation Group",
                     "Evaluation Category",
                     "Evaluation Benchmark")
knitr::kable(bm.table)

```

***

# Indicator Estimates by Reporting Unit for Monitoring Objectives

This section identifies the proportion of land or water resources that is achieving desired values known as benchmarks. This section provides further detail about each row of the table in the previous section. This information can be used as supporting information for the conclusions drawn from the previous section. Specifically, for each indicator, the following are reported:

  * Graph of proportion of the area achieving desired conditions (benchmarks) relative to the required proportion in the monitoring objective
* Table showing the proportion of the area achieving desired conditions (benchmarks) as well as the indicator, benchmark, and required proportion of the landscape
* Map of the reporting unit relative to the sample frame

For the details of each monitoring objective, see "Goals, Objectives, Benchmarks, and Results by Reporting Unit."  Monitoring objectives were determined by the field office in their Monitoring Design Worksheet and/or Terrestrial Benchmark Tool.


```{r conditionResults, echo=FALSE, error=FALSE, message=FALSE, warning=FALSE, results='asis'}
cat("\n## Results by Reporting Unit {.tabset .tabset-fade .tabset-pills}\n")
for (lev in ru.levels) { # by reporting unit level

  #cat("\n",msg1,"\n")
  data.rulevel <- analysis %>% dplyr::filter(Type == lev)
  rus <- unique(data.rulevel$Subpopulation)
  for (ru in rus) {
    cat("\n###",lev,": ",ru,"\n")
    data.ru <- data.rulevel %>% dplyr::filter(Subpopulation==ru)
    mqs <- unique(data.ru$MANAGEMENT.QUESTION)
    for (mq in mqs) { # by specific reporting unit
      cat("\n#### Goal/Management Question: ", mq, "\n")
      data.mq <- data.ru %>% dplyr::filter(MANAGEMENT.QUESTION == mq)
      Indicators <- unique(data.mq$Indicator)
      for (ind in Indicators) {  # by indicator
        ind.name <- indicator.lut$indicator.name[indicator.lut$indicator.tdat == ind]
        cat("\n#### Indicator: ", indicator.lut$indicator.name[indicator.lut$indicator.tdat == ind], "\n")
        ## Look up the landscape threshold value for the RU and indicator
        req.prop <- benchmarks.sum[benchmarks.sum$indicator.tdat == ind & !is.na(benchmarks.sum$Required.Proportion), 4]
        req.prop <- as.numeric(req.prop[1, 1])
        
        if (!is.na(req.prop)) {
          req.prop <- req.prop*100
        } else {
          req.prop <- 0
        }
        
        g <- indicatorPlot(df = analysis,
                           ru = lev,
                           subpop = ru,
                           indicator = ind,
                           indicator.lut = indicator.lut,
                           mq = mq,
                           threshold = req.prop)
        #m <- indicatorMap(lev,ru,reporting.units.spdf,project.area.spdf)
        m <- indicatorMap(level = lev,
                          ru = ru,
                          repunits.spdf = reporting.units.spdf,
                          prjarea.spdf = project.area.spdf,
                          samplepts.spdf = points.benchmarked.spdf)
        txt <- grid::textGrob(label = msgGrob,
                              just = "centre",
                              gp = grid::gpar(fontsize = 18,
                                              col = "red"))
        gridExtra::grid.arrange(gridExtra::arrangeGrob(m, txt, nrow = 2),
                                g,
                                ncol = 2,
                                widths = c(1, 3))
        cat("\n")
        cat("\n",msg1,"\n")
        cat("\n#### Results Table\n")
        cat(pander::pander(indicatorTable(df = analysis,
                                          ru = lev,
                                          subpop = ru,
                                          indicator = ind,
                                          mq = mq,
                                          conf.level = conf.level)))
        cat("\n",msg2,"\n")
        cat("\n***\n")
      }
    }
  }
}


```
***
# Appendices

  * [Methods for terrestrial data collection](http://www.landscapetoolbox.org/manuals/monitoring-manual/)
* [Sample design information](http://aim.landscapetoolbox.org/analysis-reporting/reporting/report-appendices/)
* [Analysis methods](http://aim.landscapetoolbox.org/analysis-reporting/reporting/report-appendices/)
* Report Inputs
+ Monitoring Design Worksheet
+ Raw data from TerrADat
+ Terrestrial Benchmark Tool
+ Sample design geodatabase
+ Reporting units spatial data
+ Remote-sensing datasets
